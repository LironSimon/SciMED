performance_score,mae,mse,r2,t_test_p_value,pipeline
8.12790469621107e-07,0.00039499062202476667,8.12790469621107e-07,0.9999168525004822,0.9966748952010132,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom xgboost import XGBRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -1.3589906844169898e-06exported_pipeline = XGBRegressor(learning_rate=0.1,max_depth=9,min_child_weight=3,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.4,verbosity=0)"
4.184818808151302e-07,0.0002862958747712135,4.184818808151302e-07,0.9999571898007128,0.996997751693216,"SelectPercentile(score_func=f_regression,percentile=77),XGBRegressor(learning_rate=0.1,max_depth=7,min_child_weight=6,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.8500000000000001,verbosity=0))"
5.379875857364314e-06,0.000437887793794961,5.379875857364314e-06,0.9994496450906171,0.9827136675194612,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom sklearn.tree import DecisionTreeRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -5.5691025545028965e-06exported_pipeline = DecisionTreeRegressor(max_depth=9,min_samples_leaf=6,min_samples_split=4)"
4.360922780546289e-07,0.00012049018914411074,4.360922780546289e-07,0.9999553882779948,0.9955635301536696,"StackingEstimator(estimator=SGDRegressor(alpha=0.01,eta0=1.0,fit_intercept=False,l1_ratio=1.0,learning_rate=""invscaling"",loss=""epsilon_insensitive"",penalty=""elasticnet"",power_t=1.0)),GradientBoostingRegressor(alpha=0.99,learning_rate=0.1,loss=""ls"",max_depth=6,max_features=1.0,min_samples_leaf=2,min_samples_split=20,n_estimators=100,subsample=0.8500000000000001))"
5.972277533127225e-07,0.0003655308274433774,5.972277533127225e-07,0.9999389043102909,0.9960588208597463,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom xgboost import XGBRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -8.680113631891056e-07exported_pipeline = XGBRegressor(learning_rate=0.1,max_depth=5,min_child_weight=4,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.6500000000000001,verbosity=0)"
1.2209520415418284e-06,0.00025672305443472283,1.2209520415418284e-06,0.9998750980565353,0.9939757662459214,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom sklearn.tree import DecisionTreeRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -8.021721439173407e-07exported_pipeline = DecisionTreeRegressor(max_depth=9,min_samples_leaf=2,min_samples_split=2)"
1.1806357480335815e-06,0.00015043105343756012,1.1806357480335815e-06,0.9998792223654689,0.9935482746509681,"make_union(        make_union(            FunctionTransformer(copy),FunctionTransformer(copy)        ),FunctionTransformer(copy)    ),RandomForestRegressor(bootstrap=False,max_features=0.7000000000000001,min_samples_leaf=2,min_samples_split=4,n_estimators=100))"
1.4343246719699336e-06,0.00036866496377906723,1.4343246719699336e-06,0.9998532702899107,0.995314957450028,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom xgboost import XGBRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -2.4654330932952026e-06exported_pipeline = XGBRegressor(learning_rate=0.5,max_depth=10,min_child_weight=4,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=1.0,verbosity=0)"
1.7497952273070873e-06,0.00018748323028305094,1.7497952273070873e-06,0.9998209980268513,0.9930693377143202,"ZeroCount(),RandomForestRegressor(bootstrap=False,max_features=0.8500000000000001,min_samples_leaf=1,min_samples_split=4,n_estimators=100))"
2.0447719226437784e-06,0.00035471488668562147,2.0447719226437784e-06,0.9997908222613251,0.9683176655641116,"SelectFromModel(estimator=ExtraTreesRegressor(max_features=0.5,n_estimators=100),threshold=0.15000000000000002),KNeighborsRegressor(n_neighbors=10,p=1,weights=""uniform""))"
2.0638171007981734e-06,0.0003833979432294768,2.0638171007981734e-06,0.9997888739622239,0.9864890009360359,"StandardScaler(),XGBRegressor(learning_rate=0.5,max_depth=6,min_child_weight=5,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.7500000000000001,verbosity=0))"
1.612759409798643e-06,0.00024581418300334703,1.612759409798643e-06,0.9998350166281957,0.9979878281700956,"StackingEstimator(estimator=RandomForestRegressor(bootstrap=False,max_features=0.9000000000000001,min_samples_leaf=3,min_samples_split=2,n_estimators=100)),RidgeCV())"
4.500926742631972e-06,0.0003955407017614441,4.500926742631972e-06,0.999539560540939,0.995252016914113,"StandardScaler(),XGBRegressor(learning_rate=0.1,max_depth=9,min_child_weight=11,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.7500000000000001,verbosity=0))"
1.8499561620979908e-06,0.0003720852027127632,1.8499561620979908e-06,0.9998107516822047,0.9909018911482839,"StackingEstimator(estimator=RandomForestRegressor(bootstrap=False,max_features=1.0,min_samples_leaf=3,min_samples_split=3,n_estimators=100)),ElasticNetCV(l1_ratio=0.35000000000000003,tol=0.01))"
2.1444212117750433e-06,0.0003562280794352214,2.1444212117750433e-06,0.9997806282574216,0.9939599077141066,"SelectPercentile(score_func=f_regression,percentile=32),XGBRegressor(learning_rate=0.1,max_depth=6,min_child_weight=10,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.8500000000000001,verbosity=0))"
1.4156786950668999e-06,0.0002609780676688447,1.4156786950668999e-06,0.999855177751198,0.993291872989442,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom sklearn.tree import DecisionTreeRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -9.150293232142329e-07exported_pipeline = DecisionTreeRegressor(max_depth=9,min_samples_leaf=2,min_samples_split=3)"
6.375940148234696e-06,0.0006052991165580732,6.375940148234696e-06,0.9993477488968989,0.9789977993773809,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom sklearn.tree import DecisionTreeRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -6.628490037667651e-06exported_pipeline = DecisionTreeRegressor(max_depth=8,min_samples_leaf=7,min_samples_split=8)"
3.712945070237554e-06,0.00044537105136295107,3.712945070237554e-06,0.9996201701299711,0.9953495613241032,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom xgboost import XGBRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -6.250061823649164e-06exported_pipeline = XGBRegressor(learning_rate=0.5,max_depth=8,min_child_weight=7,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.6000000000000001,verbosity=0)"
2.1620864045462895e-06,0.0004723455287672002,2.1620864045462895e-06,0.9997788211291858,0.9954876489026734,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom xgboost import XGBRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -5.3319699623199074e-06exported_pipeline = XGBRegressor(learning_rate=0.5,max_depth=5,min_child_weight=6,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.6500000000000001,verbosity=0)"
3.3149159398944754e-06,0.00046201247469318074,3.3149159398944754e-06,0.9996608880371811,0.9933638266385203,"as npimport pandas as pdfrom sklearn.model_selection import train_test_splitfrom xgboost import XGBRegressor# NOTE: Make sure that the outcome column is labeled 'target' in the data filetpot_data = pd.read_csv('PATH/TO/DATA/FILE',sep='COLUMN_SEPARATOR',dtype=np.float64)features = tpot_data.drop('target',axis=1)training_features,testing_features,training_target,testing_target = \            train_test_split(features,tpot_data['target'],random_state=None)# Average CV score on the training set was: -4.329973582031308e-06exported_pipeline = XGBRegressor(learning_rate=0.5,max_depth=9,min_child_weight=4,n_estimators=100,n_jobs=1,objective=""reg:squarederror"",subsample=0.6500000000000001,verbosity=0)"
